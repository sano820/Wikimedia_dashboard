# docker/compose.yml
services:
  kafka:
    image: confluentinc/cp-kafka:7.6.1

    ports:
      - "9092:9092" # host에서 접근 필요하면
      - "29092:29092"
    environment:
      # -------------------------
      # ✅ KRaft 필수 설정 (ZooKeeper 제거)
      # -------------------------
      # 브로커/컨트롤러 역할을 한 노드에서 같이 수행 (combined mode: 로컬 실험용)
      KAFKA_PROCESS_ROLES: "broker,controller"

      # KRaft에서는 broker.id 대신 node.id 사용
      KAFKA_NODE_ID: 1

      # 컨트롤러 쿼럼(raft 합의 그룹) 구성: 단일 노드면 1대만 등록
      # 형식: {node.id}@{host}:{controller_port}
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:29093"

      # 컨트롤러가 사용할 리스너 이름
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"

      # KRaft 클러스터는 CLUSTER_ID가 필요함 (클러스터 메타데이터 초기화에 사용)
      # 보통 /bin/kafka-storage random-uuid 로 생성한 값을 넣음 (문서 예시 참고)
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"

      # -------------------------
      # ✅ Listener 구성 (내부/외부 + 컨트롤러 리스너 추가)
      # -------------------------
      # 컨테이너 내부에서 바인딩할 리스너들
      # - PLAINTEXT: 도커 네트워크 내부 통신(다른 컨테이너들이 kafka:9092로 접속)
      # - PLAINTEXT_HOST: 호스트(로컬PC)에서 접속할 포트(여기선 29092로 열어둠)
      # - CONTROLLER: KRaft 컨트롤러 통신 전용 포트
      KAFKA_LISTENERS: "PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093"

      # 클라이언트에게 "어디로 접속해야 하는지" 알려주는 주소(중요)
      # - 도커 내부 컨테이너들은 kafka:9092로
      # - 호스트(너의 로컬 PC)는 localhost:29092로
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092"

      # 리스너 이름별 프로토콜 매핑 (CONTROLLER도 추가!)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT"

      # 브로커들끼리 통신할 때 사용할 리스너 이름(단일 노드라도 보통 명시)
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"

      # -------------------------
      # 기존 단일 브로커 개발용 옵션 유지
      # -------------------------
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 20s
    networks:
      - wikimedia-network

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: wiki-kafka-ui
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: wiki-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    networks:
      - wikimedia-network

    # (선택) 데이터 유지하고 싶으면 볼륨 마운트 권장
    # volumes:
    #   - ./kafka-data:/var/lib/kafka/data


  producer:
    build:
      context: ..
      dockerfile: docker/dockerfile
    depends_on:
      - kafka
    env_file:
      - ../.env
    command: ["python", "producer.py"]
    networks:
      - wikimedia-network

  consumer:
    build:
      context: ..
      dockerfile: docker/dockerfile
    depends_on:
      - kafka
    env_file:
      - ../.env
    volumes:
      - ../data:/data
    command: ["python", "consumer.py"]
    networks:
      - wikimedia-network
      
  spark-master:
    image: apache/spark:3.5.8
    container_name: wiki-spark-master
    hostname: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    ports:
      - "7077:7077"   # Master 포트 (Worker/Driver 연결용)
      - "4040:4040"   # Spark Application UI (앱 실행 중에만)
      - "8081:8080"   # Master Web UI
    environment:
      SPARK_MODE: master
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
    volumes:
      - ../data:/data
      - ../src:/app
    networks:
      - wikimedia-network

  spark-streaming:
    build:
      context: ..
      dockerfile: docker/dockerfile.spark
    depends_on:
      - kafka
      - redis
    user: "0:0"
    working_dir: /app
    volumes:
      - ../src:/app/src:ro
      - ../checkpoints:/app/checkpoints
      - ../output:/app/output
      - ../data:/app/data
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: wiki-events
      SPARK_CHECKPOINT_DIR: /app/checkpoints/wiki
      REDIS_HOST: redis
      REDIS_PORT: 6379
    command: >
      /opt/spark/bin/spark-submit
      --master local[*]
      /app/src/spark_streaming.py
    restart: unless-stopped
    networks:
      - wikimedia-network

  redis:
    image: redis:7-alpine
    container_name: wiki-redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - wikimedia-network
  backend:
    build:
      context: ..
      dockerfile: docker/dockerfile.backend
    container_name: wiki-backend
    ports:
      - "8000:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
       # 키들은 기본값이 spark 코드랑 맞아서 없어도 됨(원하면 명시 가능)
      # - KEY_TOTAL=metrics:events_total_10m_10s
      # - KEY_BY_TYPE=metrics:events_by_type_10m_10s
      # - KEY_BOT=metrics:bot_ratio_1m
      # - KEY_TOP=metrics:top_domain_5m_top10
      
      # 프론트 개발 단계면 아래도 추천(필요 시 api_server.py에서 사용)
      # - CORS_ORIGINS=http://localhost:5173,http://localhost:3000
    depends_on:
      redis:
        condition: service_healthy
    networks:
      - wikimedia-network

networks:
  wikimedia-network:
    driver: bridge

volumes:
  redis-data: